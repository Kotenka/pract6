import numpy as np
import matplotlib.pyplot as plt
import sys

X = np.array([ # массив аргументов
    [0, 1],
    [1, 0],
    [1, 1],
    [0, 0]
])
y = np.array([ # массив значений
    [1],
    [1],
    [0],
    [0]
])
# unit - единица измерения
num_i_units = 2
num_h_units = 2
num_o_units = 1

learning_rate = 0.1 # 0.001, 0.01 <- Magic values Скорость обучения
reg_param = 0 # 0.001, 0.01 <- Magic values Пока не поняла че это
max_iter = 5000 # 5000 <- Magic value максимальное колличество иттерация
m = 4 # Количество обучающих примеров

# Модель должна быть более подходящей, чтобы делать прогнозы.
np.random.seed(1)
# random.seed позволяет изменить число, которое передается
# в random для генерации случайного числа, а т.к. "случайные" числа выдаются одним
# и тем же алгоритмом, то при одинаковом параметре в random.seed будут и одинаковые "случайные" числа.
W1 = np.random.normal(0, 1, (num_h_units, num_i_units)) # 2x2
W2 = np.random.normal(0, 1, (num_o_units, num_h_units)) # 1x2
# numpy.random.normal (loc = 0.0, scale = 1.0, size = None): создает массив заданной формы
# и заполняет его случайными значениями, которые фактически являются
# частью нормального (гауссовского) распределения.

B1 = np.random.random((num_h_units, 1)) # 2x1
B2 = np.random.random((num_o_units, 1)) # 1x1
# class random.Random([seed]) Класс, реализующий генератор псевдослучайных
# чисел по умолчанию, используемый модулем random.
def sigmoid(z, derv=False): #функция сигмоид
    if derv: return z * (1 - z) # если дерв все так же фолс,
    # то возвращаем з по этой формуле
    return 1 / (1 + np.exp(-z)) # иначе по этой формуле (сигмоида)
# Сигмо́ида — это гладкая монотонная возрастающая нелинейная функция,
# имеющая форму буквы «S», которая часто применяется для «сглаживания»
# значений некоторой величины. Часто под сигмоидой понимают логистическую функцию.

def forward(x, predict=False): # функция переадресации
    a1 = x.reshape(x.shape[0], 1) # Получение обучающего примера в виде вектора столбца.

    z2 = W1.dot(a1) + B1 # 2x2 * 2x1 + 2x1 = 2x1
    a2 = sigmoid(z2) # 2x1

    z3 = W2.dot(a2) + B2 # 1x2 * 2x1 + 1x1 = 1x1
    a3 = sigmoid(z3) #1x1

    if predict: return a3 # если predict(прогноз)все так же фолс,
    # то возвращаем 3 переменные
    return (a1, a2, a3)
# иначе
# зачем дважды объявлять эти переменные?
# они уже в цикле есть
# оно и без них работает
#dW1 = 0
#dW2 = 0

#dB1 = 0
#dB2 = 0

cost = np.zeros((max_iter, 1)) # массив нулей
# Функция zeros() возвращает новый массив указанной формы и типа, заполненный нулями.
# Параметры:
# shape - целое число, список или кортеж целых чисел
# Задает размеры необходимого массива - целое число или кортеж целых чисел.

for i in range(max_iter): # цикл фор от 0 до 5000
   #локальные переменные внутри цикла
    c = 0

    dW1 = 0
    dW2 = 0

    dB1 = 0
    dB2 = 0
    for j in range(m): # цикл внутри цикла от 0 до 4 m = 4 # Количество обучающих примеров
        sys.stdout.write("\rIteration: {} and {}".format(i + 1, j + 1))
        # вывод на экран кол-во итераций и кол-во последних выведенных

        # Forward Prop. веростяность переадресации???
        a0 = X[j].reshape(X[j].shape[0], 1) # 2x1
        # Функция reshape() изменяет форму массива без изменения его данных.
        # Функция shape() возвращает форму массива.
        z1 = W1.dot(a0) + B1 # 2x2 * 2x1 + 2x1 = 2x1
        a1 = sigmoid(z1) # 2x1
        # Функция dot() вычисляет скалярное произведение двух массивов.

        z2 = W2.dot(a1) + B2 # 1x2 * 2x1 + 1x1 = 1x1
        a2 = sigmoid(z2) # 1x1

        # Обратная вероятность
        dz2 = a2 - y[j] # 1x1
        dW2 += dz2 * a1.T # 1x1 * 1x2 = 1x2
        # .T меняет порядок расположения осей, вместо того чтобы
        # переключать последние две. Это означает, что если
        # Ваш массив x является 3-D, то x. T совпадает с x.
        # transpose((2, 1, 0)). Если вы хотите переключить
        # последние две оси, то в этом случае вы должны сделать x. transpose ((0, 2, 1))

        dz1 = np.multiply((W2.T * dz2), sigmoid(a1, derv=True)) # (2x1 * 1x1) .* 2x1 = 2x1
        # Функция multiply() вычисляет поэлементное произведение массивов x1 и x2.
        dW1 += dz1.dot(a0.T) # 2x1 * 1x2 = 2x2

        dB1 += dz1 # 2x1 накапливаем значения
        dB2 += dz2 # 1x1

        c = c + (-(y[j] * np.log(a2)) - ((1 - y[j]) * np.log(1 - a2)))
        # c + (-y*log a) - (1 -y * log (1-a))
        sys.stdout.flush() # робновление текста.
    W1 = W1 - learning_rate * (dW1 / m) + ( (reg_param / m) * W1)
   # W1 - 0.1 * (dW1/4) + (0/4)* W1
    W2 = W2 - learning_rate * (dW2 / m) + ( (reg_param / m) * W2)

    B1 = B1 - learning_rate * (dB1 / m)
    B2 = B2 - learning_rate * (dB2 / m)
    cost[i] = (c / m) + ( # присваиваем значение i-му элементу массива
        (reg_param / (2 * m)) * 
        (
            # Функция power() выполняет возведение элементов
            # из массива x1 в степень элементов из массива x2.
            np.sum(np.power(W1, 2)) + 
            np.sum(np.power(W2, 2))
        )
    )


for x in X:
    print("\n")
    print(x)
    print(forward(x, predict=True))

plt.plot(range(max_iter), cost)
plt.xlabel("Iterations")
plt.ylabel("Cost")
plt.show()
